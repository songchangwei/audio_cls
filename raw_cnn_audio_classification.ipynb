{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用原始语音信号和卷积神经网络进行语音分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来自论文：VERY DEEP CONVOLUTIONAL NEURAL NETWORKS FOR RAW WAVEFORMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集类，包括预处理，论文中没有使用数据增强\n",
    "预处理包括两个步骤：\n",
    "1. 降采样：为提高计算速度，将音频波形下采样到 8kHz。这一步骤减少了数据量，使得后续处理更加高效。\n",
    "2. 标准化：对音频数据进行标准化处理，使其均值为 0，方差为 1。标准化有助于模型更快地收敛，提高训练效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(file_path):\n",
    "    # 加载音频文件，将采样率设置为8kHz\n",
    "    audio, sr = librosa.load(file_path, sr=8000)\n",
    "    # 标准化音频数据\n",
    "    audio = librosa.util.normalize(audio)\n",
    "    return audio.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, data, audio_dir):\n",
    "        \"\"\"\n",
    "        初始化数据集类\n",
    "        :param data_csv_path: 包含音频文件信息和标签的CSV文件路径\n",
    "        :param audio_dir: 音频文件所在的文件夹路径\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.audio_dir = audio_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        audio_filename = row['filename']\n",
    "        label = row['target']\n",
    "        audio_file_path = os.path.join(self.audio_dir, audio_filename)\n",
    "        audio = preprocess_audio(audio_file_path)\n",
    "        return torch.from_numpy(audio).float(), torch.tensor(label).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "train_data                filename  target\n",
      "0     3-145387-A-29.wav      29\n",
      "1      1-50455-A-44.wav      44\n",
      "2     3-103599-A-25.wav      25\n",
      "3       2-69131-B-5.wav       5\n",
      "4      2-103424-A-3.wav       3\n",
      "...                 ...     ...\n",
      "1595  3-188726-A-35.wav      35\n",
      "1596  4-159609-A-14.wav      14\n",
      "1597  3-118487-A-26.wav      26\n",
      "1598  4-188191-C-29.wav      29\n",
      "1599   3-187549-A-6.wav       6\n",
      "\n",
      "[1600 rows x 2 columns]\n",
      "val_data               filename  target\n",
      "0    5-221950-A-22.wav      22\n",
      "1     1-79220-A-17.wav      17\n",
      "2    4-165845-A-45.wav      45\n",
      "3    3-130330-A-22.wav      22\n",
      "4    4-157297-A-21.wav      21\n",
      "..                 ...     ...\n",
      "395  3-144891-A-19.wav      19\n",
      "396  4-156827-A-46.wav      46\n",
      "397   5-198891-D-8.wav       8\n",
      "398   1-52290-A-30.wav      30\n",
      "399  2-125966-A-11.wav      11\n",
      "\n",
      "[400 rows x 2 columns]\n",
      "Batch Index: 0\n",
      "Data Shape: torch.Size([32, 1, 40000])\n",
      "Target Shape: torch.Size([32])\n",
      "First Data Sample: tensor([[-0.0045, -0.0185, -0.0281,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "First Target Sample: tensor(49)\n"
     ]
    }
   ],
   "source": [
    "data_csv_path = \"/home/nlp/songcw/data/ESC-50-master/meta/esc50.csv\"\n",
    "audio_dir = \"/home/nlp/songcw/data/ESC-50-master/audio/\"\n",
    "\n",
    "# 读取数据集信息\n",
    "data = pd.read_csv(data_csv_path)\n",
    "audio_filenames = data['filename'].tolist()\n",
    "labels = data['target'].tolist()\n",
    "\n",
    "print(np.unique(labels))\n",
    "\n",
    "audio_files = [\"/home/nlp/songcw/data/ESC-50-master/audio/\" + filename for filename in audio_filenames]\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_filenames, val_filenames, train_labels, val_labels = train_test_split(audio_filenames, labels,\n",
    "                                                                              test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = pd.DataFrame({'filename': train_filenames, 'target': train_labels})\n",
    "val_data = pd.DataFrame({'filename': val_filenames, 'target': val_labels})\n",
    "\n",
    "print('train_data',train_data)\n",
    "print('val_data',val_data)\n",
    "\n",
    "train_dataset = SpeechDataset(train_data, audio_dir)\n",
    "val_dataset = SpeechDataset(val_data, audio_dir)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(\"Batch Index:\", batch_idx)\n",
    "    print(\"Data Shape:\", data.shape)\n",
    "    print(\"Target Shape:\", target.shape)\n",
    "    # 假设数据是图像或音频等多维数据，可以查看第一个样本的内容\n",
    "    print(\"First Data Sample:\", data[0])\n",
    "    print(\"First Target Sample:\", target[0])\n",
    "    # 只查看第一个批次就退出循环\n",
    "    if batch_idx == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M5模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # 卷积层\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size // 2)\n",
    "        # 批量归一化层\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        # ReLU激活函数\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # 第一个卷积层\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size // 2)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 第二个卷积层\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, 1, padding=kernel_size // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        # 跳跃连接\n",
    "        if stride!= 1 or in_channels!= out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 1, stride),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "        x += residual\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RawWaveformCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(RawWaveformCNN, self).__init__()\n",
    "        # 第一层卷积层，感受野为80，步长为4，256个滤波器\n",
    "        self.layer1 = BasicBlock(1, 256, 80, 4)\n",
    "        # 最大池化层，池化核大小为4x1\n",
    "        self.maxpool1 = nn.MaxPool1d(4)\n",
    "        # 卷积层，感受野为3，256个滤波器\n",
    "        self.layer2 = BasicBlock(256, 256, 3)\n",
    "        self.maxpool2 = nn.MaxPool1d(4)\n",
    "        # 卷积层，感受野为3，512个滤波器\n",
    "        self.layer3 = BasicBlock(256, 512, 3)\n",
    "        self.maxpool3 = nn.MaxPool1d(4)\n",
    "        # 卷积层，感受野为3，512个滤波器\n",
    "        self.layer4 = BasicBlock(512, 512, 3)\n",
    "        # 全局平均池化层\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        # 全连接层用于分类\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RawWaveformCNNResidual(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(RawWaveformCNNResidual, self).__init__()\n",
    "        # 第一层卷积层，感受野为80，步长为4，48个滤波器\n",
    "        self.layer1 = BasicBlock(1, 48, 80, 4)\n",
    "        self.maxpool1 = nn.MaxPool1d(4)\n",
    "        # 残差块，包含两个卷积层，感受野为3，64个滤波器\n",
    "        self.resblock1 = ResidualBlock(48, 64, 3)\n",
    "        self.maxpool2 = nn.MaxPool1d(4)\n",
    "        self.resblock2 = ResidualBlock(64, 64, 3)\n",
    "        self.maxpool3 = nn.MaxPool1d(4)\n",
    "        self.resblock3 = ResidualBlock(64, 64, 3)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.resblock1(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M18模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M18Model(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(M18Model, self).__init__()\n",
    "        # 第一层卷积层\n",
    "        self.layer1 = nn.Conv1d(1, 48, 80, 4)\n",
    "        self.bn1 = nn.BatchNorm1d(48)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool1d(4)\n",
    "        # 第二层卷积层（三个堆叠的卷积层）\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(48, 64, 3, 1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, 3, 1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, 3, 1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.maxpool2 = nn.MaxPool1d(4)\n",
    "        # 第三层卷积层（四个堆叠的卷积层）\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, 3, 1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, 3, 1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, 3, 1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, 3, 1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.maxpool3 = nn.MaxPool1d(4)\n",
    "        # 第四层卷积层（四个堆叠的卷积层）\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv1d(128, 512, 3, 1, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, 3, 1, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, 3, 1, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, 3, 1, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.maxpool4 = nn.MaxPool1d(4)\n",
    "        # 全局平均池化层\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        # 全连接层用于分类\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看M5模型结构和模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawWaveformCNN(\n",
      "  (layer1): BasicBlock(\n",
      "    (conv): Conv1d(1, 256, kernel_size=(80,), stride=(4,), padding=(40,))\n",
      "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer2): BasicBlock(\n",
      "    (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer3): BasicBlock(\n",
      "    (conv): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer4): BasicBlock(\n",
      "    (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): Linear(in_features=512, out_features=50, bias=True)\n",
      ")\n",
      "torch.Size([1, 50])\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = RawWaveformCNN(50)  # 或 RawWaveformCNNResidual()\n",
    "print(model)\n",
    "# 随机生成输入数据（假设输入音频长度为40000）\n",
    "input_data = torch.randn(1, 1, 40000)\n",
    "# 前向传播\n",
    "output = model(input_data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看M18模型结构和模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M18Model(\n",
      "  (layer1): Conv1d(1, 48, kernel_size=(80,), stride=(4,))\n",
      "  (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (maxpool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv1d(48, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (10): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): Linear(in_features=512, out_features=50, bias=True)\n",
      ")\n",
      "torch.Size([32, 50])\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = M18Model(50)  # 或 RawWaveformCNNResidual()\n",
    "print(model)\n",
    "# 随机生成输入数据（假设输入音频长度为40000）\n",
    "input_data = torch.randn(32, 1, 40000)\n",
    "# 前向传播\n",
    "output = model(input_data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型检查点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, loss, filename='RawWaveformCNNResidual.pth'):\n",
    "    \"\"\"\n",
    "    保存模型检查点。\n",
    "\n",
    "    参数：\n",
    "    - model: 要保存的模型\n",
    "    - optimizer: 模型对应的优化器\n",
    "    - epoch: 当前的epoch\n",
    "    - loss: 当前的损失\n",
    "    - filename: 检查点保存的文件名\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载模型检查点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename='RawWaveformCNNResidual.pth'):\n",
    "    \"\"\"\n",
    "    加载模型检查点。\n",
    "\n",
    "    参数：\n",
    "    - model: 初始化的模型实例\n",
    "    - optimizer: 初始化的优化器实例\n",
    "    - filename: 检查点文件名\n",
    "\n",
    "    返回：\n",
    "    - epoch: 上次保存时的epoch\n",
    "    - loss: 上次保存时的损失\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return epoch, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建训练和验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, epochs, learning_rate,filename = 'RawWaveformCNNResidual.pth'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_epoch_loss = val_loss / len(val_loader)\n",
    "        val_epoch_acc = val_correct / val_total\n",
    "        if val_epoch_acc > best_val_acc:\n",
    "            best_val_acc = val_epoch_acc\n",
    "            save_checkpoint(model, optimizer, epoch, val_epoch_loss,filename=filename)\n",
    "\n",
    "        print(f'Epoch {epoch + 1} Train Loss: {epoch_loss:.4f} Train Acc: {epoch_acc:.4f} '\n",
    "              f'Val Loss: {val_epoch_loss:.4f} Val Acc: {val_epoch_acc:.4f}')\n",
    "    return best_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 50  # ESC-50数据集有50个类别\n",
    "model = RawWaveformCNNResidual(num_classes)\n",
    "epochs = 200\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss: 3.6412 Train Acc: 0.0969 Val Loss: 3.4341 Val Acc: 0.1275\n",
      "Epoch 2 Train Loss: 3.1082 Train Acc: 0.1819 Val Loss: 3.0290 Val Acc: 0.1950\n",
      "Epoch 3 Train Loss: 2.8479 Train Acc: 0.2275 Val Loss: 2.9116 Val Acc: 0.2125\n",
      "Epoch 4 Train Loss: 2.6720 Train Acc: 0.2712 Val Loss: 2.7297 Val Acc: 0.2700\n",
      "Epoch 5 Train Loss: 2.5349 Train Acc: 0.3100 Val Loss: 2.8098 Val Acc: 0.2550\n",
      "Epoch 6 Train Loss: 2.4081 Train Acc: 0.3638 Val Loss: 2.4369 Val Acc: 0.3400\n",
      "Epoch 7 Train Loss: 2.2737 Train Acc: 0.3762 Val Loss: 2.5519 Val Acc: 0.3225\n",
      "Epoch 8 Train Loss: 2.1862 Train Acc: 0.3969 Val Loss: 2.4921 Val Acc: 0.3075\n",
      "Epoch 9 Train Loss: 2.1115 Train Acc: 0.4181 Val Loss: 2.4110 Val Acc: 0.3425\n",
      "Epoch 10 Train Loss: 2.0328 Train Acc: 0.4450 Val Loss: 2.2520 Val Acc: 0.3950\n",
      "Epoch 11 Train Loss: 1.9437 Train Acc: 0.4575 Val Loss: 2.2780 Val Acc: 0.3875\n",
      "Epoch 12 Train Loss: 1.8224 Train Acc: 0.5050 Val Loss: 2.1839 Val Acc: 0.4200\n",
      "Epoch 13 Train Loss: 1.7516 Train Acc: 0.5194 Val Loss: 2.1098 Val Acc: 0.4500\n",
      "Epoch 14 Train Loss: 1.7147 Train Acc: 0.5300 Val Loss: 2.2526 Val Acc: 0.3975\n",
      "Epoch 15 Train Loss: 1.6650 Train Acc: 0.5319 Val Loss: 2.1050 Val Acc: 0.4650\n",
      "Epoch 16 Train Loss: 1.6157 Train Acc: 0.5575 Val Loss: 2.1534 Val Acc: 0.4275\n",
      "Epoch 17 Train Loss: 1.5983 Train Acc: 0.5575 Val Loss: 2.1373 Val Acc: 0.4350\n",
      "Epoch 18 Train Loss: 1.4991 Train Acc: 0.5894 Val Loss: 2.1699 Val Acc: 0.3900\n",
      "Epoch 19 Train Loss: 1.4834 Train Acc: 0.5837 Val Loss: 2.0084 Val Acc: 0.4800\n",
      "Epoch 20 Train Loss: 1.4330 Train Acc: 0.6012 Val Loss: 1.9554 Val Acc: 0.4875\n",
      "Epoch 21 Train Loss: 1.3968 Train Acc: 0.6238 Val Loss: 1.8875 Val Acc: 0.4975\n",
      "Epoch 22 Train Loss: 1.3552 Train Acc: 0.6188 Val Loss: 1.9561 Val Acc: 0.4950\n",
      "Epoch 23 Train Loss: 1.2547 Train Acc: 0.6631 Val Loss: 1.9765 Val Acc: 0.4725\n",
      "Epoch 24 Train Loss: 1.2948 Train Acc: 0.6562 Val Loss: 1.9207 Val Acc: 0.5000\n",
      "Epoch 25 Train Loss: 1.2223 Train Acc: 0.6663 Val Loss: 2.0924 Val Acc: 0.4675\n",
      "Epoch 26 Train Loss: 1.2145 Train Acc: 0.6669 Val Loss: 1.9533 Val Acc: 0.5050\n",
      "Epoch 27 Train Loss: 1.1462 Train Acc: 0.6719 Val Loss: 1.9016 Val Acc: 0.5450\n",
      "Epoch 28 Train Loss: 1.1838 Train Acc: 0.6719 Val Loss: 1.8569 Val Acc: 0.5425\n",
      "Epoch 29 Train Loss: 1.0977 Train Acc: 0.6887 Val Loss: 1.9756 Val Acc: 0.5000\n",
      "Epoch 30 Train Loss: 1.0851 Train Acc: 0.7050 Val Loss: 1.7753 Val Acc: 0.5800\n",
      "Epoch 31 Train Loss: 1.0306 Train Acc: 0.7181 Val Loss: 1.8089 Val Acc: 0.5350\n",
      "Epoch 32 Train Loss: 1.0312 Train Acc: 0.7175 Val Loss: 1.8267 Val Acc: 0.5325\n",
      "Epoch 33 Train Loss: 1.0381 Train Acc: 0.7100 Val Loss: 1.7673 Val Acc: 0.5575\n",
      "Epoch 34 Train Loss: 0.9713 Train Acc: 0.7231 Val Loss: 1.8635 Val Acc: 0.5300\n",
      "Epoch 35 Train Loss: 0.9563 Train Acc: 0.7312 Val Loss: 1.8753 Val Acc: 0.5400\n",
      "Epoch 36 Train Loss: 0.9416 Train Acc: 0.7319 Val Loss: 1.8975 Val Acc: 0.5325\n",
      "Epoch 37 Train Loss: 0.9083 Train Acc: 0.7519 Val Loss: 1.8268 Val Acc: 0.5475\n",
      "Epoch 38 Train Loss: 0.8736 Train Acc: 0.7500 Val Loss: 1.8927 Val Acc: 0.5600\n",
      "Epoch 39 Train Loss: 0.8533 Train Acc: 0.7606 Val Loss: 1.9184 Val Acc: 0.5600\n",
      "Epoch 40 Train Loss: 0.8551 Train Acc: 0.7488 Val Loss: 1.8480 Val Acc: 0.5575\n",
      "Epoch 41 Train Loss: 0.8274 Train Acc: 0.7819 Val Loss: 1.7651 Val Acc: 0.5625\n",
      "Epoch 42 Train Loss: 0.7932 Train Acc: 0.7750 Val Loss: 1.7414 Val Acc: 0.5700\n",
      "Epoch 43 Train Loss: 0.8209 Train Acc: 0.7775 Val Loss: 1.8627 Val Acc: 0.5525\n",
      "Epoch 44 Train Loss: 0.7793 Train Acc: 0.7731 Val Loss: 1.9526 Val Acc: 0.5375\n",
      "Epoch 45 Train Loss: 0.8213 Train Acc: 0.7744 Val Loss: 1.9308 Val Acc: 0.5200\n",
      "Epoch 46 Train Loss: 0.7229 Train Acc: 0.8113 Val Loss: 1.7775 Val Acc: 0.5800\n",
      "Epoch 47 Train Loss: 0.7196 Train Acc: 0.7944 Val Loss: 1.8480 Val Acc: 0.5525\n",
      "Epoch 48 Train Loss: 0.7149 Train Acc: 0.8006 Val Loss: 1.8997 Val Acc: 0.5725\n",
      "Epoch 49 Train Loss: 0.6817 Train Acc: 0.8163 Val Loss: 1.8928 Val Acc: 0.5325\n",
      "Epoch 50 Train Loss: 0.6976 Train Acc: 0.7994 Val Loss: 1.7925 Val Acc: 0.5950\n",
      "Epoch 51 Train Loss: 0.6517 Train Acc: 0.8156 Val Loss: 1.8865 Val Acc: 0.5675\n",
      "Epoch 52 Train Loss: 0.6407 Train Acc: 0.8200 Val Loss: 1.9766 Val Acc: 0.5425\n",
      "Epoch 53 Train Loss: 0.5834 Train Acc: 0.8406 Val Loss: 1.7114 Val Acc: 0.5725\n",
      "Epoch 54 Train Loss: 0.5817 Train Acc: 0.8456 Val Loss: 2.0484 Val Acc: 0.5275\n",
      "Epoch 55 Train Loss: 0.6355 Train Acc: 0.8237 Val Loss: 2.0748 Val Acc: 0.5475\n",
      "Epoch 56 Train Loss: 0.5675 Train Acc: 0.8456 Val Loss: 1.7508 Val Acc: 0.6000\n",
      "Epoch 57 Train Loss: 0.5446 Train Acc: 0.8550 Val Loss: 1.8745 Val Acc: 0.5625\n",
      "Epoch 58 Train Loss: 0.5691 Train Acc: 0.8438 Val Loss: 1.8279 Val Acc: 0.6125\n",
      "Epoch 59 Train Loss: 0.5679 Train Acc: 0.8381 Val Loss: 1.7883 Val Acc: 0.5750\n",
      "Epoch 60 Train Loss: 0.5583 Train Acc: 0.8425 Val Loss: 2.0856 Val Acc: 0.5075\n",
      "Epoch 61 Train Loss: 0.4974 Train Acc: 0.8712 Val Loss: 1.8356 Val Acc: 0.5750\n",
      "Epoch 62 Train Loss: 0.4906 Train Acc: 0.8681 Val Loss: 2.0146 Val Acc: 0.5575\n",
      "Epoch 63 Train Loss: 0.5104 Train Acc: 0.8644 Val Loss: 1.9669 Val Acc: 0.5550\n",
      "Epoch 64 Train Loss: 0.5084 Train Acc: 0.8700 Val Loss: 1.8713 Val Acc: 0.5950\n",
      "Epoch 65 Train Loss: 0.4907 Train Acc: 0.8744 Val Loss: 1.8938 Val Acc: 0.5550\n",
      "Epoch 66 Train Loss: 0.5068 Train Acc: 0.8562 Val Loss: 2.0161 Val Acc: 0.5400\n",
      "Epoch 67 Train Loss: 0.4443 Train Acc: 0.8869 Val Loss: 1.7735 Val Acc: 0.5900\n",
      "Epoch 68 Train Loss: 0.4207 Train Acc: 0.8906 Val Loss: 1.7433 Val Acc: 0.6225\n",
      "Epoch 69 Train Loss: 0.4260 Train Acc: 0.8812 Val Loss: 2.2225 Val Acc: 0.5050\n",
      "Epoch 70 Train Loss: 0.4150 Train Acc: 0.8938 Val Loss: 1.9132 Val Acc: 0.5600\n",
      "Epoch 71 Train Loss: 0.4278 Train Acc: 0.8850 Val Loss: 1.9120 Val Acc: 0.5925\n",
      "Epoch 72 Train Loss: 0.3664 Train Acc: 0.9137 Val Loss: 1.8439 Val Acc: 0.6125\n",
      "Epoch 73 Train Loss: 0.3817 Train Acc: 0.9012 Val Loss: 1.9444 Val Acc: 0.5700\n",
      "Epoch 74 Train Loss: 0.3680 Train Acc: 0.9125 Val Loss: 1.8394 Val Acc: 0.6050\n",
      "Epoch 75 Train Loss: 0.3497 Train Acc: 0.9169 Val Loss: 2.0826 Val Acc: 0.5900\n",
      "Epoch 76 Train Loss: 0.3947 Train Acc: 0.9000 Val Loss: 2.2500 Val Acc: 0.5250\n",
      "Epoch 77 Train Loss: 0.3731 Train Acc: 0.9081 Val Loss: 2.0631 Val Acc: 0.5475\n",
      "Epoch 78 Train Loss: 0.3604 Train Acc: 0.9019 Val Loss: 1.7931 Val Acc: 0.6425\n",
      "Epoch 79 Train Loss: 0.3337 Train Acc: 0.9263 Val Loss: 2.0404 Val Acc: 0.5975\n",
      "Epoch 80 Train Loss: 0.3379 Train Acc: 0.9194 Val Loss: 2.2294 Val Acc: 0.5450\n",
      "Epoch 81 Train Loss: 0.3069 Train Acc: 0.9294 Val Loss: 2.1258 Val Acc: 0.5775\n",
      "Epoch 82 Train Loss: 0.3358 Train Acc: 0.9113 Val Loss: 1.9671 Val Acc: 0.5900\n",
      "Epoch 83 Train Loss: 0.3723 Train Acc: 0.8969 Val Loss: 2.3554 Val Acc: 0.5300\n",
      "Epoch 84 Train Loss: 0.3566 Train Acc: 0.9087 Val Loss: 1.9348 Val Acc: 0.6150\n",
      "Epoch 85 Train Loss: 0.3178 Train Acc: 0.9213 Val Loss: 2.2479 Val Acc: 0.5875\n",
      "Epoch 86 Train Loss: 0.2964 Train Acc: 0.9375 Val Loss: 2.0171 Val Acc: 0.5700\n",
      "Epoch 87 Train Loss: 0.3190 Train Acc: 0.9156 Val Loss: 2.2057 Val Acc: 0.5525\n",
      "Epoch 88 Train Loss: 0.3196 Train Acc: 0.9137 Val Loss: 2.1277 Val Acc: 0.5800\n",
      "Epoch 89 Train Loss: 0.3199 Train Acc: 0.9150 Val Loss: 2.2375 Val Acc: 0.5625\n",
      "Epoch 90 Train Loss: 0.3028 Train Acc: 0.9256 Val Loss: 2.1724 Val Acc: 0.5775\n",
      "Epoch 91 Train Loss: 0.2512 Train Acc: 0.9487 Val Loss: 2.0451 Val Acc: 0.6175\n",
      "Epoch 92 Train Loss: 0.2341 Train Acc: 0.9494 Val Loss: 2.0820 Val Acc: 0.6175\n",
      "Epoch 93 Train Loss: 0.2465 Train Acc: 0.9444 Val Loss: 1.8505 Val Acc: 0.6100\n",
      "Epoch 94 Train Loss: 0.2203 Train Acc: 0.9513 Val Loss: 1.8746 Val Acc: 0.6325\n",
      "Epoch 95 Train Loss: 0.2530 Train Acc: 0.9400 Val Loss: 2.3937 Val Acc: 0.5775\n",
      "Epoch 96 Train Loss: 0.2398 Train Acc: 0.9487 Val Loss: 2.3181 Val Acc: 0.5675\n",
      "Epoch 97 Train Loss: 0.2538 Train Acc: 0.9369 Val Loss: 2.2182 Val Acc: 0.5875\n",
      "Epoch 98 Train Loss: 0.2503 Train Acc: 0.9406 Val Loss: 2.1731 Val Acc: 0.5975\n",
      "Epoch 99 Train Loss: 0.2181 Train Acc: 0.9487 Val Loss: 2.4315 Val Acc: 0.5050\n",
      "Epoch 100 Train Loss: 0.2635 Train Acc: 0.9306 Val Loss: 2.1653 Val Acc: 0.6025\n",
      "Epoch 101 Train Loss: 0.2612 Train Acc: 0.9344 Val Loss: 2.3795 Val Acc: 0.5600\n",
      "Epoch 102 Train Loss: 0.2362 Train Acc: 0.9469 Val Loss: 2.3259 Val Acc: 0.5500\n",
      "Epoch 103 Train Loss: 0.2663 Train Acc: 0.9331 Val Loss: 2.1459 Val Acc: 0.6000\n",
      "Epoch 104 Train Loss: 0.2604 Train Acc: 0.9331 Val Loss: 2.1090 Val Acc: 0.6000\n",
      "Epoch 105 Train Loss: 0.2287 Train Acc: 0.9463 Val Loss: 2.1788 Val Acc: 0.6125\n",
      "Epoch 106 Train Loss: 0.2178 Train Acc: 0.9487 Val Loss: 2.2490 Val Acc: 0.5750\n",
      "Epoch 107 Train Loss: 0.2120 Train Acc: 0.9513 Val Loss: 2.0750 Val Acc: 0.6225\n",
      "Epoch 108 Train Loss: 0.1632 Train Acc: 0.9700 Val Loss: 2.3283 Val Acc: 0.5775\n",
      "Epoch 109 Train Loss: 0.1486 Train Acc: 0.9694 Val Loss: 2.0736 Val Acc: 0.6600\n",
      "Epoch 110 Train Loss: 0.1507 Train Acc: 0.9688 Val Loss: 2.1949 Val Acc: 0.6075\n",
      "Epoch 111 Train Loss: 0.1438 Train Acc: 0.9756 Val Loss: 2.1637 Val Acc: 0.6100\n",
      "Epoch 112 Train Loss: 0.1473 Train Acc: 0.9738 Val Loss: 2.3330 Val Acc: 0.5650\n",
      "Epoch 113 Train Loss: 0.1681 Train Acc: 0.9619 Val Loss: 2.1560 Val Acc: 0.5725\n",
      "Epoch 114 Train Loss: 0.2006 Train Acc: 0.9475 Val Loss: 2.2166 Val Acc: 0.6000\n",
      "Epoch 115 Train Loss: 0.1951 Train Acc: 0.9563 Val Loss: 2.3034 Val Acc: 0.5800\n",
      "Epoch 116 Train Loss: 0.2018 Train Acc: 0.9481 Val Loss: 2.3801 Val Acc: 0.5550\n",
      "Epoch 117 Train Loss: 0.2278 Train Acc: 0.9400 Val Loss: 2.5355 Val Acc: 0.5375\n",
      "Epoch 118 Train Loss: 0.2447 Train Acc: 0.9325 Val Loss: 2.3620 Val Acc: 0.5575\n",
      "Epoch 119 Train Loss: 0.1698 Train Acc: 0.9644 Val Loss: 2.1738 Val Acc: 0.6200\n",
      "Epoch 120 Train Loss: 0.1152 Train Acc: 0.9788 Val Loss: 2.0672 Val Acc: 0.6225\n",
      "Epoch 121 Train Loss: 0.1046 Train Acc: 0.9806 Val Loss: 2.1270 Val Acc: 0.5950\n",
      "Epoch 122 Train Loss: 0.1142 Train Acc: 0.9806 Val Loss: 2.1963 Val Acc: 0.6100\n",
      "Epoch 123 Train Loss: 0.1173 Train Acc: 0.9788 Val Loss: 2.1784 Val Acc: 0.6175\n",
      "Epoch 124 Train Loss: 0.1307 Train Acc: 0.9762 Val Loss: 2.1423 Val Acc: 0.5825\n",
      "Epoch 125 Train Loss: 0.1835 Train Acc: 0.9600 Val Loss: 2.4889 Val Acc: 0.5200\n",
      "Epoch 126 Train Loss: 0.2178 Train Acc: 0.9369 Val Loss: 2.1436 Val Acc: 0.6175\n",
      "Epoch 127 Train Loss: 0.1870 Train Acc: 0.9550 Val Loss: 2.4175 Val Acc: 0.5650\n",
      "Epoch 128 Train Loss: 0.1983 Train Acc: 0.9444 Val Loss: 2.4019 Val Acc: 0.5875\n",
      "Epoch 129 Train Loss: 0.1848 Train Acc: 0.9481 Val Loss: 2.2062 Val Acc: 0.5875\n",
      "Epoch 130 Train Loss: 0.1696 Train Acc: 0.9575 Val Loss: 2.4860 Val Acc: 0.5600\n",
      "Epoch 131 Train Loss: 0.1346 Train Acc: 0.9719 Val Loss: 2.3227 Val Acc: 0.6175\n",
      "Epoch 132 Train Loss: 0.1068 Train Acc: 0.9806 Val Loss: 2.2935 Val Acc: 0.6125\n",
      "Epoch 133 Train Loss: 0.0921 Train Acc: 0.9850 Val Loss: 2.1658 Val Acc: 0.6250\n",
      "Epoch 134 Train Loss: 0.0697 Train Acc: 0.9931 Val Loss: 2.1853 Val Acc: 0.6425\n",
      "Epoch 135 Train Loss: 0.0814 Train Acc: 0.9825 Val Loss: 2.1541 Val Acc: 0.6175\n",
      "Epoch 136 Train Loss: 0.0754 Train Acc: 0.9856 Val Loss: 2.3447 Val Acc: 0.6225\n",
      "Epoch 137 Train Loss: 0.0902 Train Acc: 0.9856 Val Loss: 2.3595 Val Acc: 0.6000\n",
      "Epoch 138 Train Loss: 0.1070 Train Acc: 0.9769 Val Loss: 2.5036 Val Acc: 0.5925\n",
      "Epoch 139 Train Loss: 0.0904 Train Acc: 0.9806 Val Loss: 2.3084 Val Acc: 0.5750\n",
      "Epoch 140 Train Loss: 0.0916 Train Acc: 0.9838 Val Loss: 2.3257 Val Acc: 0.6025\n",
      "Epoch 141 Train Loss: 0.0981 Train Acc: 0.9769 Val Loss: 2.2908 Val Acc: 0.6000\n",
      "Epoch 142 Train Loss: 0.1299 Train Acc: 0.9706 Val Loss: 2.2972 Val Acc: 0.6000\n",
      "Epoch 143 Train Loss: 0.1314 Train Acc: 0.9744 Val Loss: 2.3842 Val Acc: 0.5875\n",
      "Epoch 144 Train Loss: 0.1639 Train Acc: 0.9487 Val Loss: 2.6618 Val Acc: 0.5400\n",
      "Epoch 145 Train Loss: 0.1545 Train Acc: 0.9637 Val Loss: 2.6017 Val Acc: 0.5450\n",
      "Epoch 146 Train Loss: 0.2081 Train Acc: 0.9431 Val Loss: 2.5842 Val Acc: 0.5500\n",
      "Epoch 147 Train Loss: 0.1944 Train Acc: 0.9375 Val Loss: 2.3105 Val Acc: 0.6150\n",
      "Epoch 148 Train Loss: 0.1412 Train Acc: 0.9669 Val Loss: 2.1340 Val Acc: 0.6150\n",
      "Epoch 149 Train Loss: 0.0834 Train Acc: 0.9869 Val Loss: 2.2600 Val Acc: 0.6350\n",
      "Epoch 150 Train Loss: 0.0744 Train Acc: 0.9881 Val Loss: 2.3893 Val Acc: 0.5925\n",
      "Epoch 151 Train Loss: 0.1013 Train Acc: 0.9769 Val Loss: 2.2068 Val Acc: 0.6400\n",
      "Epoch 152 Train Loss: 0.0873 Train Acc: 0.9806 Val Loss: 2.3338 Val Acc: 0.6050\n",
      "Epoch 153 Train Loss: 0.1173 Train Acc: 0.9725 Val Loss: 2.7096 Val Acc: 0.5675\n",
      "Epoch 154 Train Loss: 0.1292 Train Acc: 0.9625 Val Loss: 2.4157 Val Acc: 0.6250\n",
      "Epoch 155 Train Loss: 0.0986 Train Acc: 0.9794 Val Loss: 2.3382 Val Acc: 0.6350\n",
      "Epoch 156 Train Loss: 0.0928 Train Acc: 0.9844 Val Loss: 2.5456 Val Acc: 0.6200\n",
      "Epoch 157 Train Loss: 0.1180 Train Acc: 0.9719 Val Loss: 2.6139 Val Acc: 0.5875\n",
      "Epoch 158 Train Loss: 0.1713 Train Acc: 0.9556 Val Loss: 3.7397 Val Acc: 0.5000\n",
      "Epoch 159 Train Loss: 0.1529 Train Acc: 0.9613 Val Loss: 2.6038 Val Acc: 0.5850\n",
      "Epoch 160 Train Loss: 0.1353 Train Acc: 0.9712 Val Loss: 2.6369 Val Acc: 0.5675\n",
      "Epoch 161 Train Loss: 0.0661 Train Acc: 0.9875 Val Loss: 2.3867 Val Acc: 0.6375\n",
      "Epoch 162 Train Loss: 0.0575 Train Acc: 0.9925 Val Loss: 2.3163 Val Acc: 0.6325\n",
      "Epoch 163 Train Loss: 0.0465 Train Acc: 0.9944 Val Loss: 2.3541 Val Acc: 0.6275\n",
      "Epoch 164 Train Loss: 0.0609 Train Acc: 0.9888 Val Loss: 3.0809 Val Acc: 0.5375\n",
      "Epoch 165 Train Loss: 0.1378 Train Acc: 0.9613 Val Loss: 3.2697 Val Acc: 0.5675\n",
      "Epoch 166 Train Loss: 0.1453 Train Acc: 0.9581 Val Loss: 3.0667 Val Acc: 0.5275\n",
      "Epoch 167 Train Loss: 0.1746 Train Acc: 0.9475 Val Loss: 3.0841 Val Acc: 0.5350\n",
      "Epoch 168 Train Loss: 0.1066 Train Acc: 0.9700 Val Loss: 2.2181 Val Acc: 0.6200\n",
      "Epoch 169 Train Loss: 0.0793 Train Acc: 0.9831 Val Loss: 3.0630 Val Acc: 0.5575\n",
      "Epoch 170 Train Loss: 0.0658 Train Acc: 0.9906 Val Loss: 2.4054 Val Acc: 0.6250\n",
      "Epoch 171 Train Loss: 0.0658 Train Acc: 0.9856 Val Loss: 2.3188 Val Acc: 0.5950\n",
      "Epoch 172 Train Loss: 0.1022 Train Acc: 0.9794 Val Loss: 2.9604 Val Acc: 0.5675\n",
      "Epoch 173 Train Loss: 0.0956 Train Acc: 0.9769 Val Loss: 2.6171 Val Acc: 0.6100\n",
      "Epoch 174 Train Loss: 0.1096 Train Acc: 0.9725 Val Loss: 2.6862 Val Acc: 0.6025\n",
      "Epoch 175 Train Loss: 0.0970 Train Acc: 0.9738 Val Loss: 2.5748 Val Acc: 0.6125\n",
      "Epoch 176 Train Loss: 0.1112 Train Acc: 0.9712 Val Loss: 2.9063 Val Acc: 0.5550\n",
      "Epoch 177 Train Loss: 0.0801 Train Acc: 0.9838 Val Loss: 2.7207 Val Acc: 0.5900\n",
      "Epoch 178 Train Loss: 0.0773 Train Acc: 0.9800 Val Loss: 2.5627 Val Acc: 0.6375\n",
      "Epoch 179 Train Loss: 0.0990 Train Acc: 0.9756 Val Loss: 2.4511 Val Acc: 0.6100\n",
      "Epoch 180 Train Loss: 0.1132 Train Acc: 0.9712 Val Loss: 2.8969 Val Acc: 0.5850\n",
      "Epoch 181 Train Loss: 0.1154 Train Acc: 0.9712 Val Loss: 2.7329 Val Acc: 0.6050\n",
      "Epoch 182 Train Loss: 0.0698 Train Acc: 0.9875 Val Loss: 2.2773 Val Acc: 0.6425\n",
      "Epoch 183 Train Loss: 0.0571 Train Acc: 0.9912 Val Loss: 2.2553 Val Acc: 0.6400\n",
      "Epoch 184 Train Loss: 0.0386 Train Acc: 0.9956 Val Loss: 2.3515 Val Acc: 0.6075\n",
      "Epoch 185 Train Loss: 0.0596 Train Acc: 0.9856 Val Loss: 2.4737 Val Acc: 0.6150\n",
      "Epoch 186 Train Loss: 0.0626 Train Acc: 0.9862 Val Loss: 2.6667 Val Acc: 0.6075\n",
      "Epoch 187 Train Loss: 0.0435 Train Acc: 0.9906 Val Loss: 2.6221 Val Acc: 0.5850\n",
      "Epoch 188 Train Loss: 0.0450 Train Acc: 0.9938 Val Loss: 2.4788 Val Acc: 0.6175\n",
      "Epoch 189 Train Loss: 0.0484 Train Acc: 0.9900 Val Loss: 2.2662 Val Acc: 0.6150\n",
      "Epoch 190 Train Loss: 0.0582 Train Acc: 0.9875 Val Loss: 2.3521 Val Acc: 0.5900\n",
      "Epoch 191 Train Loss: 0.0575 Train Acc: 0.9850 Val Loss: 2.1948 Val Acc: 0.6150\n",
      "Epoch 192 Train Loss: 0.0591 Train Acc: 0.9881 Val Loss: 2.4500 Val Acc: 0.6075\n",
      "Epoch 193 Train Loss: 0.1836 Train Acc: 0.9481 Val Loss: 3.8127 Val Acc: 0.4800\n",
      "Epoch 194 Train Loss: 0.1040 Train Acc: 0.9744 Val Loss: 2.4218 Val Acc: 0.6225\n",
      "Epoch 195 Train Loss: 0.0627 Train Acc: 0.9850 Val Loss: 2.4777 Val Acc: 0.6275\n",
      "Epoch 196 Train Loss: 0.0415 Train Acc: 0.9931 Val Loss: 2.5115 Val Acc: 0.6500\n",
      "Epoch 197 Train Loss: 0.0389 Train Acc: 0.9938 Val Loss: 2.5235 Val Acc: 0.5850\n",
      "Epoch 198 Train Loss: 0.0494 Train Acc: 0.9919 Val Loss: 2.3620 Val Acc: 0.6425\n",
      "Epoch 199 Train Loss: 0.0569 Train Acc: 0.9894 Val Loss: 2.4992 Val Acc: 0.6150\n",
      "Epoch 200 Train Loss: 0.0692 Train Acc: 0.9856 Val Loss: 2.6099 Val Acc: 0.6025\n",
      "最好的结果为：ACC= 0.66\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = train_model(model, train_loader, val_loader, epochs, learning_rate)\n",
    "print(\"最好的结果为：ACC=\",best_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练M18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss: 3.5594 Train Acc: 0.0856 Val Loss: 3.6327 Val Acc: 0.0675\n",
      "Epoch 2 Train Loss: 3.0592 Train Acc: 0.1500 Val Loss: 3.4105 Val Acc: 0.1075\n",
      "Epoch 3 Train Loss: 2.7823 Train Acc: 0.2112 Val Loss: 2.8032 Val Acc: 0.1900\n",
      "Epoch 4 Train Loss: 2.6430 Train Acc: 0.2325 Val Loss: 3.3124 Val Acc: 0.1700\n",
      "Epoch 5 Train Loss: 2.5289 Train Acc: 0.2687 Val Loss: 3.6559 Val Acc: 0.1450\n",
      "Epoch 6 Train Loss: 2.3957 Train Acc: 0.3081 Val Loss: 2.4588 Val Acc: 0.3000\n",
      "Epoch 7 Train Loss: 2.3460 Train Acc: 0.3194 Val Loss: 2.8387 Val Acc: 0.2525\n",
      "Epoch 8 Train Loss: 2.2397 Train Acc: 0.3500 Val Loss: 2.2826 Val Acc: 0.3325\n",
      "Epoch 9 Train Loss: 2.1204 Train Acc: 0.3856 Val Loss: 2.6018 Val Acc: 0.3025\n",
      "Epoch 10 Train Loss: 2.0677 Train Acc: 0.3881 Val Loss: 2.4812 Val Acc: 0.2950\n",
      "Epoch 11 Train Loss: 1.9166 Train Acc: 0.4556 Val Loss: 2.1842 Val Acc: 0.3175\n",
      "Epoch 12 Train Loss: 1.8539 Train Acc: 0.4512 Val Loss: 2.7688 Val Acc: 0.2250\n",
      "Epoch 13 Train Loss: 1.8223 Train Acc: 0.4656 Val Loss: 2.8348 Val Acc: 0.3200\n",
      "Epoch 14 Train Loss: 1.6938 Train Acc: 0.4938 Val Loss: 2.2243 Val Acc: 0.3425\n",
      "Epoch 15 Train Loss: 1.6668 Train Acc: 0.4956 Val Loss: 1.9912 Val Acc: 0.4200\n",
      "Epoch 16 Train Loss: 1.5936 Train Acc: 0.5306 Val Loss: 2.6488 Val Acc: 0.3275\n",
      "Epoch 17 Train Loss: 1.5504 Train Acc: 0.5387 Val Loss: 2.6216 Val Acc: 0.3575\n",
      "Epoch 18 Train Loss: 1.4670 Train Acc: 0.5763 Val Loss: 2.1801 Val Acc: 0.3675\n",
      "Epoch 19 Train Loss: 1.4124 Train Acc: 0.5744 Val Loss: 2.0836 Val Acc: 0.4250\n",
      "Epoch 20 Train Loss: 1.3408 Train Acc: 0.6062 Val Loss: 2.0827 Val Acc: 0.4600\n",
      "Epoch 21 Train Loss: 1.3017 Train Acc: 0.5975 Val Loss: 2.1402 Val Acc: 0.4175\n",
      "Epoch 22 Train Loss: 1.3009 Train Acc: 0.5950 Val Loss: 2.0616 Val Acc: 0.4325\n",
      "Epoch 23 Train Loss: 1.2266 Train Acc: 0.6119 Val Loss: 2.1087 Val Acc: 0.4075\n",
      "Epoch 24 Train Loss: 1.1680 Train Acc: 0.6519 Val Loss: 2.2228 Val Acc: 0.3975\n",
      "Epoch 25 Train Loss: 1.1147 Train Acc: 0.6650 Val Loss: 1.9839 Val Acc: 0.4975\n",
      "Epoch 26 Train Loss: 1.0557 Train Acc: 0.6894 Val Loss: 2.7632 Val Acc: 0.4175\n",
      "Epoch 27 Train Loss: 1.0265 Train Acc: 0.6819 Val Loss: 1.7337 Val Acc: 0.4975\n",
      "Epoch 28 Train Loss: 1.0020 Train Acc: 0.6950 Val Loss: 1.8860 Val Acc: 0.4925\n",
      "Epoch 29 Train Loss: 0.9937 Train Acc: 0.6913 Val Loss: 1.7751 Val Acc: 0.5050\n",
      "Epoch 30 Train Loss: 0.9246 Train Acc: 0.7125 Val Loss: 1.8473 Val Acc: 0.5075\n",
      "Epoch 31 Train Loss: 0.9465 Train Acc: 0.7144 Val Loss: 2.3281 Val Acc: 0.3850\n",
      "Epoch 32 Train Loss: 0.9066 Train Acc: 0.7188 Val Loss: 2.3043 Val Acc: 0.4875\n",
      "Epoch 33 Train Loss: 0.8646 Train Acc: 0.7269 Val Loss: 1.8868 Val Acc: 0.5475\n",
      "Epoch 34 Train Loss: 0.7521 Train Acc: 0.7688 Val Loss: 1.8857 Val Acc: 0.5150\n",
      "Epoch 35 Train Loss: 0.7229 Train Acc: 0.7819 Val Loss: 1.9338 Val Acc: 0.4975\n",
      "Epoch 36 Train Loss: 0.7026 Train Acc: 0.7937 Val Loss: 2.0477 Val Acc: 0.4600\n",
      "Epoch 37 Train Loss: 0.7063 Train Acc: 0.7825 Val Loss: 1.9606 Val Acc: 0.4675\n",
      "Epoch 38 Train Loss: 0.6363 Train Acc: 0.8081 Val Loss: 1.7891 Val Acc: 0.5625\n",
      "Epoch 39 Train Loss: 0.6360 Train Acc: 0.8081 Val Loss: 2.3041 Val Acc: 0.4400\n",
      "Epoch 40 Train Loss: 0.6173 Train Acc: 0.8081 Val Loss: 2.5801 Val Acc: 0.4950\n",
      "Epoch 41 Train Loss: 0.5692 Train Acc: 0.8394 Val Loss: 1.9715 Val Acc: 0.5275\n",
      "Epoch 42 Train Loss: 0.5794 Train Acc: 0.8144 Val Loss: 1.9561 Val Acc: 0.5600\n",
      "Epoch 43 Train Loss: 0.5282 Train Acc: 0.8500 Val Loss: 2.4307 Val Acc: 0.4850\n",
      "Epoch 44 Train Loss: 0.5497 Train Acc: 0.8369 Val Loss: 2.0551 Val Acc: 0.5300\n",
      "Epoch 45 Train Loss: 0.5224 Train Acc: 0.8394 Val Loss: 2.0131 Val Acc: 0.5525\n",
      "Epoch 46 Train Loss: 0.5430 Train Acc: 0.8219 Val Loss: 2.0108 Val Acc: 0.5250\n",
      "Epoch 47 Train Loss: 0.4879 Train Acc: 0.8650 Val Loss: 1.8876 Val Acc: 0.5450\n",
      "Epoch 48 Train Loss: 0.4131 Train Acc: 0.8781 Val Loss: 2.1972 Val Acc: 0.5600\n",
      "Epoch 49 Train Loss: 0.3372 Train Acc: 0.9025 Val Loss: 1.9894 Val Acc: 0.5050\n",
      "Epoch 50 Train Loss: 0.4019 Train Acc: 0.8888 Val Loss: 1.8573 Val Acc: 0.5200\n",
      "Epoch 51 Train Loss: 0.3652 Train Acc: 0.8919 Val Loss: 1.9687 Val Acc: 0.5150\n",
      "Epoch 52 Train Loss: 0.3564 Train Acc: 0.8919 Val Loss: 1.8609 Val Acc: 0.5775\n",
      "Epoch 53 Train Loss: 0.4065 Train Acc: 0.8862 Val Loss: 1.9270 Val Acc: 0.5325\n",
      "Epoch 54 Train Loss: 0.3762 Train Acc: 0.8912 Val Loss: 1.8223 Val Acc: 0.5750\n",
      "Epoch 55 Train Loss: 0.3446 Train Acc: 0.8988 Val Loss: 2.8384 Val Acc: 0.4475\n",
      "Epoch 56 Train Loss: 0.3288 Train Acc: 0.9106 Val Loss: 2.2563 Val Acc: 0.5225\n",
      "Epoch 57 Train Loss: 0.3467 Train Acc: 0.9000 Val Loss: 2.0177 Val Acc: 0.5700\n",
      "Epoch 58 Train Loss: 0.3115 Train Acc: 0.9181 Val Loss: 2.1758 Val Acc: 0.5400\n",
      "Epoch 59 Train Loss: 0.3240 Train Acc: 0.9062 Val Loss: 2.2023 Val Acc: 0.5325\n",
      "Epoch 60 Train Loss: 0.2611 Train Acc: 0.9256 Val Loss: 2.2601 Val Acc: 0.5250\n",
      "Epoch 61 Train Loss: 0.2038 Train Acc: 0.9431 Val Loss: 1.9610 Val Acc: 0.5375\n",
      "Epoch 62 Train Loss: 0.1571 Train Acc: 0.9681 Val Loss: 2.5087 Val Acc: 0.5025\n",
      "Epoch 63 Train Loss: 0.1838 Train Acc: 0.9569 Val Loss: 2.2041 Val Acc: 0.5525\n",
      "Epoch 64 Train Loss: 0.2076 Train Acc: 0.9425 Val Loss: 2.1431 Val Acc: 0.5500\n",
      "Epoch 65 Train Loss: 0.2478 Train Acc: 0.9287 Val Loss: 2.2157 Val Acc: 0.5325\n",
      "Epoch 66 Train Loss: 0.2102 Train Acc: 0.9437 Val Loss: 2.5058 Val Acc: 0.5125\n",
      "Epoch 67 Train Loss: 0.2666 Train Acc: 0.9269 Val Loss: 2.5972 Val Acc: 0.5075\n",
      "Epoch 68 Train Loss: 0.2440 Train Acc: 0.9394 Val Loss: 2.0101 Val Acc: 0.5350\n",
      "Epoch 69 Train Loss: 0.1835 Train Acc: 0.9481 Val Loss: 2.4914 Val Acc: 0.5250\n",
      "Epoch 70 Train Loss: 0.2528 Train Acc: 0.9319 Val Loss: 2.1932 Val Acc: 0.5175\n",
      "Epoch 71 Train Loss: 0.1680 Train Acc: 0.9613 Val Loss: 2.1205 Val Acc: 0.5575\n",
      "Epoch 72 Train Loss: 0.1819 Train Acc: 0.9531 Val Loss: 2.3935 Val Acc: 0.5125\n",
      "Epoch 73 Train Loss: 0.1496 Train Acc: 0.9613 Val Loss: 2.1076 Val Acc: 0.5700\n",
      "Epoch 74 Train Loss: 0.1931 Train Acc: 0.9487 Val Loss: 2.2144 Val Acc: 0.5150\n",
      "Epoch 75 Train Loss: 0.1956 Train Acc: 0.9387 Val Loss: 2.2056 Val Acc: 0.5575\n",
      "Epoch 76 Train Loss: 0.2263 Train Acc: 0.9363 Val Loss: 2.7668 Val Acc: 0.4650\n",
      "Epoch 77 Train Loss: 0.2669 Train Acc: 0.9250 Val Loss: 2.7057 Val Acc: 0.4450\n",
      "Epoch 78 Train Loss: 0.3643 Train Acc: 0.8906 Val Loss: 2.5451 Val Acc: 0.4925\n",
      "Epoch 79 Train Loss: 0.2533 Train Acc: 0.9300 Val Loss: 2.2871 Val Acc: 0.5400\n",
      "Epoch 80 Train Loss: 0.2033 Train Acc: 0.9437 Val Loss: 2.7259 Val Acc: 0.4950\n",
      "Epoch 81 Train Loss: 0.2120 Train Acc: 0.9437 Val Loss: 2.4527 Val Acc: 0.5750\n",
      "Epoch 82 Train Loss: 0.1371 Train Acc: 0.9600 Val Loss: 2.2654 Val Acc: 0.6150\n",
      "Epoch 83 Train Loss: 0.0961 Train Acc: 0.9800 Val Loss: 2.2443 Val Acc: 0.6125\n",
      "Epoch 84 Train Loss: 0.0697 Train Acc: 0.9881 Val Loss: 2.1363 Val Acc: 0.5800\n",
      "Epoch 85 Train Loss: 0.0785 Train Acc: 0.9825 Val Loss: 2.4400 Val Acc: 0.5750\n",
      "Epoch 86 Train Loss: 0.0592 Train Acc: 0.9881 Val Loss: 2.3231 Val Acc: 0.5700\n",
      "Epoch 87 Train Loss: 0.0577 Train Acc: 0.9894 Val Loss: 2.4656 Val Acc: 0.5650\n",
      "Epoch 88 Train Loss: 0.1070 Train Acc: 0.9681 Val Loss: 2.2839 Val Acc: 0.5775\n",
      "Epoch 89 Train Loss: 0.0506 Train Acc: 0.9906 Val Loss: 2.1218 Val Acc: 0.5625\n",
      "Epoch 90 Train Loss: 0.0519 Train Acc: 0.9912 Val Loss: 2.2644 Val Acc: 0.5650\n",
      "Epoch 91 Train Loss: 0.0740 Train Acc: 0.9781 Val Loss: 2.7385 Val Acc: 0.5525\n",
      "Epoch 92 Train Loss: 0.0830 Train Acc: 0.9769 Val Loss: 2.7252 Val Acc: 0.5425\n",
      "Epoch 93 Train Loss: 0.1287 Train Acc: 0.9681 Val Loss: 2.1281 Val Acc: 0.5625\n",
      "Epoch 94 Train Loss: 0.0945 Train Acc: 0.9744 Val Loss: 2.6125 Val Acc: 0.5650\n",
      "Epoch 95 Train Loss: 0.1627 Train Acc: 0.9513 Val Loss: 2.9923 Val Acc: 0.4700\n",
      "Epoch 96 Train Loss: 0.2688 Train Acc: 0.9106 Val Loss: 2.6366 Val Acc: 0.5225\n",
      "Epoch 97 Train Loss: 0.1979 Train Acc: 0.9450 Val Loss: 2.6726 Val Acc: 0.4875\n",
      "Epoch 98 Train Loss: 0.2066 Train Acc: 0.9281 Val Loss: 2.7573 Val Acc: 0.5275\n",
      "Epoch 99 Train Loss: 0.1160 Train Acc: 0.9700 Val Loss: 2.4522 Val Acc: 0.5325\n",
      "Epoch 100 Train Loss: 0.1613 Train Acc: 0.9556 Val Loss: 2.9831 Val Acc: 0.5200\n",
      "Epoch 101 Train Loss: 0.1559 Train Acc: 0.9575 Val Loss: 2.8181 Val Acc: 0.4375\n",
      "Epoch 102 Train Loss: 0.1126 Train Acc: 0.9694 Val Loss: 2.7351 Val Acc: 0.5575\n",
      "Epoch 103 Train Loss: 0.0589 Train Acc: 0.9900 Val Loss: 2.3731 Val Acc: 0.5750\n",
      "Epoch 104 Train Loss: 0.0377 Train Acc: 0.9938 Val Loss: 2.2679 Val Acc: 0.5950\n",
      "Epoch 105 Train Loss: 0.0255 Train Acc: 0.9950 Val Loss: 2.3007 Val Acc: 0.5825\n",
      "Epoch 106 Train Loss: 0.0344 Train Acc: 0.9925 Val Loss: 2.3730 Val Acc: 0.5825\n",
      "Epoch 107 Train Loss: 0.0381 Train Acc: 0.9938 Val Loss: 2.6964 Val Acc: 0.5500\n",
      "Epoch 108 Train Loss: 0.0475 Train Acc: 0.9906 Val Loss: 2.5383 Val Acc: 0.5200\n",
      "Epoch 109 Train Loss: 0.0298 Train Acc: 0.9962 Val Loss: 2.3901 Val Acc: 0.5450\n",
      "Epoch 110 Train Loss: 0.0909 Train Acc: 0.9769 Val Loss: 2.9324 Val Acc: 0.5650\n",
      "Epoch 111 Train Loss: 0.1260 Train Acc: 0.9650 Val Loss: 2.9417 Val Acc: 0.5475\n",
      "Epoch 112 Train Loss: 0.1858 Train Acc: 0.9500 Val Loss: 3.0006 Val Acc: 0.5250\n",
      "Epoch 113 Train Loss: 0.2456 Train Acc: 0.9319 Val Loss: 3.1640 Val Acc: 0.4500\n",
      "Epoch 114 Train Loss: 0.3797 Train Acc: 0.8962 Val Loss: 4.4826 Val Acc: 0.4300\n",
      "Epoch 115 Train Loss: 0.3438 Train Acc: 0.8912 Val Loss: 3.1507 Val Acc: 0.4825\n",
      "Epoch 116 Train Loss: 0.1862 Train Acc: 0.9450 Val Loss: 2.9147 Val Acc: 0.4925\n",
      "Epoch 117 Train Loss: 0.1236 Train Acc: 0.9656 Val Loss: 2.3904 Val Acc: 0.5800\n",
      "Epoch 118 Train Loss: 0.0852 Train Acc: 0.9769 Val Loss: 2.7273 Val Acc: 0.5375\n",
      "Epoch 119 Train Loss: 0.0664 Train Acc: 0.9831 Val Loss: 2.4197 Val Acc: 0.5750\n",
      "Epoch 120 Train Loss: 0.0460 Train Acc: 0.9894 Val Loss: 2.4560 Val Acc: 0.5700\n",
      "Epoch 121 Train Loss: 0.0427 Train Acc: 0.9888 Val Loss: 2.6049 Val Acc: 0.5700\n",
      "Epoch 122 Train Loss: 0.0647 Train Acc: 0.9862 Val Loss: 2.6632 Val Acc: 0.5450\n",
      "Epoch 123 Train Loss: 0.0493 Train Acc: 0.9862 Val Loss: 2.6207 Val Acc: 0.5425\n",
      "Epoch 124 Train Loss: 0.0330 Train Acc: 0.9938 Val Loss: 2.6063 Val Acc: 0.5600\n",
      "Epoch 125 Train Loss: 0.0298 Train Acc: 0.9925 Val Loss: 2.2776 Val Acc: 0.5900\n",
      "Epoch 126 Train Loss: 0.0463 Train Acc: 0.9894 Val Loss: 2.9966 Val Acc: 0.5650\n",
      "Epoch 127 Train Loss: 0.1059 Train Acc: 0.9694 Val Loss: 2.6029 Val Acc: 0.5500\n",
      "Epoch 128 Train Loss: 0.1107 Train Acc: 0.9681 Val Loss: 2.8644 Val Acc: 0.5400\n",
      "Epoch 129 Train Loss: 0.1156 Train Acc: 0.9681 Val Loss: 2.5528 Val Acc: 0.5750\n",
      "Epoch 130 Train Loss: 0.1329 Train Acc: 0.9581 Val Loss: 3.4533 Val Acc: 0.4575\n",
      "Epoch 131 Train Loss: 0.1944 Train Acc: 0.9406 Val Loss: 2.7315 Val Acc: 0.5700\n",
      "Epoch 132 Train Loss: 0.1046 Train Acc: 0.9706 Val Loss: 3.2580 Val Acc: 0.5050\n",
      "Epoch 133 Train Loss: 0.1337 Train Acc: 0.9656 Val Loss: 3.4625 Val Acc: 0.4825\n",
      "Epoch 134 Train Loss: 0.1071 Train Acc: 0.9731 Val Loss: 2.7463 Val Acc: 0.5375\n",
      "Epoch 135 Train Loss: 0.0780 Train Acc: 0.9794 Val Loss: 2.6269 Val Acc: 0.5400\n",
      "Epoch 136 Train Loss: 0.0727 Train Acc: 0.9812 Val Loss: 2.9099 Val Acc: 0.5475\n",
      "Epoch 137 Train Loss: 0.0511 Train Acc: 0.9850 Val Loss: 2.9856 Val Acc: 0.5425\n",
      "Epoch 138 Train Loss: 0.0571 Train Acc: 0.9844 Val Loss: 2.6631 Val Acc: 0.5850\n",
      "Epoch 139 Train Loss: 0.0531 Train Acc: 0.9925 Val Loss: 3.1678 Val Acc: 0.4925\n",
      "Epoch 140 Train Loss: 0.2369 Train Acc: 0.9344 Val Loss: 4.0135 Val Acc: 0.5125\n",
      "Epoch 141 Train Loss: 0.1443 Train Acc: 0.9556 Val Loss: 3.0245 Val Acc: 0.5275\n",
      "Epoch 142 Train Loss: 0.1275 Train Acc: 0.9600 Val Loss: 2.8393 Val Acc: 0.4925\n",
      "Epoch 143 Train Loss: 0.1000 Train Acc: 0.9706 Val Loss: 2.4419 Val Acc: 0.5525\n",
      "Epoch 144 Train Loss: 0.0802 Train Acc: 0.9806 Val Loss: 2.4556 Val Acc: 0.5850\n",
      "Epoch 145 Train Loss: 0.0536 Train Acc: 0.9875 Val Loss: 2.3711 Val Acc: 0.5850\n",
      "Epoch 146 Train Loss: 0.0356 Train Acc: 0.9912 Val Loss: 2.5492 Val Acc: 0.5525\n",
      "Epoch 147 Train Loss: 0.0346 Train Acc: 0.9925 Val Loss: 2.5937 Val Acc: 0.5650\n",
      "Epoch 148 Train Loss: 0.0195 Train Acc: 0.9969 Val Loss: 2.3236 Val Acc: 0.6150\n",
      "Epoch 149 Train Loss: 0.0154 Train Acc: 0.9981 Val Loss: 2.4262 Val Acc: 0.5875\n",
      "Epoch 150 Train Loss: 0.0098 Train Acc: 0.9988 Val Loss: 2.3918 Val Acc: 0.5950\n",
      "Epoch 151 Train Loss: 0.0073 Train Acc: 0.9994 Val Loss: 2.3396 Val Acc: 0.6350\n",
      "Epoch 152 Train Loss: 0.0061 Train Acc: 1.0000 Val Loss: 2.2762 Val Acc: 0.6000\n",
      "Epoch 153 Train Loss: 0.0048 Train Acc: 1.0000 Val Loss: 2.2602 Val Acc: 0.6200\n",
      "Epoch 154 Train Loss: 0.0080 Train Acc: 0.9994 Val Loss: 2.3751 Val Acc: 0.6200\n",
      "Epoch 155 Train Loss: 0.0123 Train Acc: 0.9981 Val Loss: 2.7788 Val Acc: 0.5550\n",
      "Epoch 156 Train Loss: 0.0111 Train Acc: 0.9988 Val Loss: 2.3236 Val Acc: 0.5975\n",
      "Epoch 157 Train Loss: 0.0166 Train Acc: 0.9956 Val Loss: 2.5369 Val Acc: 0.5575\n",
      "Epoch 158 Train Loss: 0.0775 Train Acc: 0.9769 Val Loss: 4.9387 Val Acc: 0.4575\n",
      "Epoch 159 Train Loss: 0.1304 Train Acc: 0.9613 Val Loss: 3.0087 Val Acc: 0.5150\n",
      "Epoch 160 Train Loss: 0.2214 Train Acc: 0.9319 Val Loss: 4.1723 Val Acc: 0.4925\n",
      "Epoch 161 Train Loss: 0.3419 Train Acc: 0.9006 Val Loss: 3.7600 Val Acc: 0.5000\n",
      "Epoch 162 Train Loss: 0.2529 Train Acc: 0.9275 Val Loss: 3.3139 Val Acc: 0.4600\n",
      "Epoch 163 Train Loss: 0.2191 Train Acc: 0.9331 Val Loss: 3.1457 Val Acc: 0.5025\n",
      "Epoch 164 Train Loss: 0.1718 Train Acc: 0.9463 Val Loss: 2.9093 Val Acc: 0.5125\n",
      "Epoch 165 Train Loss: 0.0685 Train Acc: 0.9819 Val Loss: 2.8350 Val Acc: 0.5600\n",
      "Epoch 166 Train Loss: 0.0399 Train Acc: 0.9919 Val Loss: 2.4123 Val Acc: 0.5850\n",
      "Epoch 167 Train Loss: 0.0321 Train Acc: 0.9931 Val Loss: 2.4958 Val Acc: 0.6000\n",
      "Epoch 168 Train Loss: 0.0419 Train Acc: 0.9894 Val Loss: 2.4574 Val Acc: 0.5950\n",
      "Epoch 169 Train Loss: 0.0222 Train Acc: 0.9956 Val Loss: 2.4332 Val Acc: 0.5750\n",
      "Epoch 170 Train Loss: 0.0243 Train Acc: 0.9944 Val Loss: 2.6495 Val Acc: 0.6000\n",
      "Epoch 171 Train Loss: 0.0241 Train Acc: 0.9950 Val Loss: 2.8994 Val Acc: 0.5675\n",
      "Epoch 172 Train Loss: 0.0247 Train Acc: 0.9962 Val Loss: 2.4227 Val Acc: 0.5925\n",
      "Epoch 173 Train Loss: 0.0281 Train Acc: 0.9956 Val Loss: 2.6116 Val Acc: 0.5850\n",
      "Epoch 174 Train Loss: 0.0529 Train Acc: 0.9825 Val Loss: 2.6395 Val Acc: 0.5700\n",
      "Epoch 175 Train Loss: 0.0281 Train Acc: 0.9931 Val Loss: 2.6806 Val Acc: 0.5775\n",
      "Epoch 176 Train Loss: 0.0173 Train Acc: 0.9962 Val Loss: 2.7624 Val Acc: 0.5650\n",
      "Epoch 177 Train Loss: 0.0234 Train Acc: 0.9956 Val Loss: 2.6610 Val Acc: 0.5925\n",
      "Epoch 178 Train Loss: 0.0229 Train Acc: 0.9944 Val Loss: 2.5521 Val Acc: 0.5550\n",
      "Epoch 179 Train Loss: 0.0148 Train Acc: 0.9975 Val Loss: 2.7505 Val Acc: 0.5750\n",
      "Epoch 180 Train Loss: 0.0189 Train Acc: 0.9956 Val Loss: 2.8267 Val Acc: 0.5800\n",
      "Epoch 181 Train Loss: 0.0131 Train Acc: 0.9975 Val Loss: 2.8407 Val Acc: 0.5750\n",
      "Epoch 182 Train Loss: 0.0180 Train Acc: 0.9962 Val Loss: 2.6604 Val Acc: 0.5650\n",
      "Epoch 183 Train Loss: 0.0125 Train Acc: 0.9975 Val Loss: 2.6957 Val Acc: 0.6150\n",
      "Epoch 184 Train Loss: 0.0166 Train Acc: 0.9975 Val Loss: 2.6389 Val Acc: 0.5875\n",
      "Epoch 185 Train Loss: 0.0231 Train Acc: 0.9950 Val Loss: 3.1208 Val Acc: 0.5800\n",
      "Epoch 186 Train Loss: 0.0455 Train Acc: 0.9881 Val Loss: 2.7923 Val Acc: 0.5975\n",
      "Epoch 187 Train Loss: 0.0406 Train Acc: 0.9906 Val Loss: 3.2982 Val Acc: 0.5700\n",
      "Epoch 188 Train Loss: 0.1029 Train Acc: 0.9706 Val Loss: 3.3317 Val Acc: 0.4575\n",
      "Epoch 189 Train Loss: 0.3732 Train Acc: 0.8881 Val Loss: 4.8054 Val Acc: 0.4000\n",
      "Epoch 190 Train Loss: 0.4008 Train Acc: 0.8844 Val Loss: 3.4341 Val Acc: 0.5325\n",
      "Epoch 191 Train Loss: 0.1885 Train Acc: 0.9469 Val Loss: 2.4569 Val Acc: 0.6175\n",
      "Epoch 192 Train Loss: 0.1479 Train Acc: 0.9581 Val Loss: 2.8703 Val Acc: 0.5350\n",
      "Epoch 193 Train Loss: 0.0772 Train Acc: 0.9788 Val Loss: 3.1958 Val Acc: 0.5650\n",
      "Epoch 194 Train Loss: 0.0499 Train Acc: 0.9850 Val Loss: 2.3688 Val Acc: 0.5725\n",
      "Epoch 195 Train Loss: 0.0482 Train Acc: 0.9888 Val Loss: 2.7281 Val Acc: 0.5600\n",
      "Epoch 196 Train Loss: 0.0384 Train Acc: 0.9925 Val Loss: 2.6892 Val Acc: 0.5875\n",
      "Epoch 197 Train Loss: 0.0544 Train Acc: 0.9875 Val Loss: 2.8218 Val Acc: 0.5450\n",
      "Epoch 198 Train Loss: 0.0515 Train Acc: 0.9838 Val Loss: 2.7692 Val Acc: 0.5750\n",
      "Epoch 199 Train Loss: 0.0222 Train Acc: 0.9969 Val Loss: 2.5367 Val Acc: 0.6050\n",
      "Epoch 200 Train Loss: 0.0219 Train Acc: 0.9950 Val Loss: 2.6017 Val Acc: 0.5800\n",
      "最好的结果为：ACC= 0.635\n"
     ]
    }
   ],
   "source": [
    "num_classes = 50  # ESC-50数据集有50个类别\n",
    "model = M18Model(num_classes)\n",
    "epochs = 200\n",
    "learning_rate = 0.001\n",
    "best_val_acc = train_model(model, train_loader, val_loader, epochs, learning_rate,'M18Model')\n",
    "print(\"最好的结果为：ACC=\",best_val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
