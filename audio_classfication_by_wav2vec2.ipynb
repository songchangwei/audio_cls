{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¯»å–MInDS-14æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "minds = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹æ•°æ®é›†ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = minds.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "        num_rows: 450\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "        num_rows: 113\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç§»é™¤æ— ç”¨ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'intent_class'],\n",
       "        num_rows: 450\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'intent_class'],\n",
       "        num_rows: 113\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds = minds.remove_columns([\"path\", \"transcription\", \"english_transcription\", \"lang_id\"])\n",
    "minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†è®©æ¨¡å‹æ›´å®¹æ˜“ä»æ ‡ç­¾ id è·å–æ ‡ç­¾åç§°ï¼Œåˆ›å»ºä¸€ä¸ªå°†æ ‡ç­¾åç§°æ˜ å°„åˆ°æ•´æ•°å’Œåå‘æ˜ å°„çš„å­—å…¸ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = minds[\"train\"].features[\"intent_class\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨å¯ä»¥å°†æ ‡ç­¾ id è½¬æ¢ä¸ºæ ‡ç­¾åç§°æˆ–è€…å°†æ ‡ç­¾åç§°è½¬åŒ–ä¸ºæ ‡ç­¾id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abroad',\n",
       " 'address',\n",
       " 'app_error',\n",
       " 'atm_limit',\n",
       " 'balance',\n",
       " 'business_loan',\n",
       " 'card_issues',\n",
       " 'cash_deposit',\n",
       " 'direct_debit',\n",
       " 'freeze',\n",
       " 'high_value_payment',\n",
       " 'joint_account',\n",
       " 'latest_transactions',\n",
       " 'pay_bill']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'app_error'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label[ str ( 2 )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŠ è½½ Wav2Vec2 ç‰¹å¾æå–å™¨æ¥å¤„ç†éŸ³é¢‘ä¿¡å·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/configuration_utils.py:311: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ•°æ®é›†çš„é‡‡æ ·ç‡ä¸º 8000khzï¼ˆå¯ä»¥åœ¨å…¶æ•°æ®é›†å¡ä¸­æ‰¾åˆ°æ­¤ä¿¡æ¯ï¼‰ï¼Œè¿™æ„å‘³ç€éœ€è¦å°†æ•°æ®é›†é‡æ–°é‡‡æ ·ä¸º 16000kHz æ‰èƒ½ä½¿ç”¨é¢„è®­ç»ƒçš„ Wav2Vec2 æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '/Users/songchangwei/.cache/huggingface/datasets/downloads/extracted/c894aeb32b2a85cb19ba4c03720f1d9ea0733781be16bc26502f0931a30b3010/en-US~ADDRESS/602baba9bb1e6d0fbce921a9.wav',\n",
       "  'array': array([2.29874277e-04, 1.51120068e-04, 1.46790771e-05, ...,\n",
       "         1.25871622e-04, 2.26960750e-04, 1.76190690e-04]),\n",
       "  'sampling_rate': 16000},\n",
       " 'intent_class': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds = minds.cast_column( \"audio\" , Audio(sampling_rate= 16_000 ))\n",
    "minds[ \"train\" ][ 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨åˆ›å»ºä¸€ä¸ªé¢„å¤„ç†å‡½æ•°ï¼š\n",
    "1. è°ƒç”¨audioåˆ—æ¥åŠ è½½ï¼Œå¹¶ä¸”å¦‚æœéœ€è¦ï¼Œé‡æ–°é‡‡æ ·éŸ³é¢‘æ–‡ä»¶ã€‚\n",
    "2. æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶çš„é‡‡æ ·ç‡æ˜¯å¦ä¸æ¨¡å‹é¢„è®­ç»ƒçš„éŸ³é¢‘æ•°æ®çš„é‡‡æ ·ç‡åŒ¹é…ã€‚å¯ä»¥åœ¨ Wav2Vec2æ¨¡å‹ä¸­æ‰¾åˆ°æ­¤ä¿¡æ¯ã€‚\n",
    "3. è®¾ç½®æœ€å¤§è¾“å…¥é•¿åº¦ä»¥æ‰¹é‡å¤„ç†è¾ƒé•¿çš„è¾“å…¥è€Œä¸æˆªæ–­å®ƒä»¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¦å°†é¢„å¤„ç†å‡½æ•°åº”ç”¨äºæ•´ä¸ªæ•°æ®é›†ï¼Œè¦ä½¿ç”¨ ğŸ¤— æ•°æ®é›†mapæ˜ å°„å‡½æ•°ã€‚å¯ä»¥é€šè¿‡è®¾ç½®ä¸ºä¸€æ¬¡å¤„ç†æ•°æ®é›†çš„å¤šä¸ªå…ƒç´ æ¥åŠ å¿«é€Ÿåº¦batched=Trueã€‚åˆ é™¤ä¸éœ€è¦çš„åˆ—ï¼Œç„¶åé‡å‘½åintent_classä¸ºlabeï¼Œå› ä¸ºè¿™æ˜¯æ¨¡å‹æœŸæœ›çš„åç§°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'intent_class'],\n",
       "        num_rows: 450\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'intent_class'],\n",
       "        num_rows: 113\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de5bb80ca674618ba5ddb21453321f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a1d0d8e4414618ae176cf4e26a3ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['intent_class', 'input_values'],\n",
       "        num_rows: 450\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['intent_class', 'input_values'],\n",
       "        num_rows: 113\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_minds = minds.map(preprocess_function, remove_columns=\"audio\", batched=True)\n",
    "encoded_minds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_values'],\n",
       "        num_rows: 450\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_values'],\n",
       "        num_rows: 113\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_minds = encoded_minds.rename_column(\"intent_class\", \"label\")\n",
    "encoded_minds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è¯„ä¼°æŒ‡æ ‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨è®­ç»ƒæœŸé—´çº³å…¥æŒ‡æ ‡é€šå¸¸æœ‰åŠ©äºè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚å¯ä»¥ä½¿ç”¨ ğŸ¤— Evaluateåº“å¿«é€ŸåŠ è½½è¯„ä¼°æ–¹æ³•ã€‚å¯¹äºæ­¤ä»»åŠ¡ï¼Œè¯·åŠ è½½accuracyæŒ‡æ ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶ååˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œä¼ é€’æ‚¨çš„é¢„æµ‹å’Œæ ‡ç­¾æ¥è®¡ç®—è¯„ä»·æŒ‡æ ‡ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨AutoModelForAudioClassificationåŠ è½½ Wav2Vec2ä»¥åŠé¢„æœŸæ ‡ç­¾æ•°é‡å’Œæ ‡ç­¾æ˜ å°„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/configuration_utils.py:311: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n",
    "num_labels = len(id2label)\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\", num_labels=num_labels, label2id=label2id, id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ­¤æ—¶ï¼Œåªå‰©ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š\n",
    "1. åœ¨TrainingArgumentsä¸­å®šä¹‰è®­ç»ƒè¶…å‚æ•°ã€‚å”¯ä¸€å¿…éœ€çš„å‚æ•°æ˜¯output_dirï¼Œå®ƒæŒ‡å®šæ¨¡å‹çš„ä¿å­˜ä½ç½®ã€‚åœ¨æ¯ä¸ªepochç»“æŸæ—¶ï¼ŒTrainerå°†è¯„ä¼°å‡†ç¡®æ€§å¹¶ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ã€‚\n",
    "2. å°†è®­ç»ƒå‚æ•°ä¸æ¨¡å‹ã€æ•°æ®é›†ã€åˆ†è¯å™¨tokenizerã€æ•°æ®æ”¶é›†å™¨data collatorå’Œè¯„ä»·æŒ‡æ ‡å‡½æ•°ä¸€èµ·ä¼ é€’ç»™Trainercompute_metricsã€‚\n",
    "3. è°ƒç”¨train()æ¥å¾®è°ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b89904c27248dca2b1f1bfcf41e0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736087a9ef92461f8b9c94418de010cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6361842155456543, 'eval_accuracy': 0.07964601769911504, 'eval_runtime': 3.5699, 'eval_samples_per_second': 31.654, 'eval_steps_per_second': 1.12, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba71e1d0b44485480bda03819e259c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.642812967300415, 'eval_accuracy': 0.07964601769911504, 'eval_runtime': 4.7722, 'eval_samples_per_second': 23.679, 'eval_steps_per_second': 0.838, 'epoch': 1.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b7a611c497414a95642346af035005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6504013538360596, 'eval_accuracy': 0.07079646017699115, 'eval_runtime': 3.6513, 'eval_samples_per_second': 30.948, 'eval_steps_per_second': 1.096, 'epoch': 2.8}\n",
      "{'loss': 12.1235, 'grad_norm': 11090.04296875, 'learning_rate': 2.222222222222222e-05, 'epoch': 3.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb005aaccd447538d6c9d57756d3c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6556034088134766, 'eval_accuracy': 0.061946902654867256, 'eval_runtime': 3.8449, 'eval_samples_per_second': 29.39, 'eval_steps_per_second': 1.04, 'epoch': 3.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9106244e1e452682bc485d9f6734e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.658604621887207, 'eval_accuracy': 0.061946902654867256, 'eval_runtime': 3.7462, 'eval_samples_per_second': 30.164, 'eval_steps_per_second': 1.068, 'epoch': 4.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bddd8f255e426383e42840d9050ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.659576177597046, 'eval_accuracy': 0.061946902654867256, 'eval_runtime': 4.787, 'eval_samples_per_second': 23.606, 'eval_steps_per_second': 0.836, 'epoch': 5.8}\n",
      "{'loss': 12.0699, 'grad_norm': 77954.1796875, 'learning_rate': 1.111111111111111e-05, 'epoch': 6.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e0d7dd90114e2ab039586b81e40f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6594295501708984, 'eval_accuracy': 0.05309734513274336, 'eval_runtime': 9.0648, 'eval_samples_per_second': 12.466, 'eval_steps_per_second': 0.441, 'epoch': 6.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93708f3815a246bd911aba7cf4712adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.659940719604492, 'eval_accuracy': 0.07079646017699115, 'eval_runtime': 3.4631, 'eval_samples_per_second': 32.629, 'eval_steps_per_second': 1.155, 'epoch': 7.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17431c60118c45c7974c98b3b67498dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6602489948272705, 'eval_accuracy': 0.07079646017699115, 'eval_runtime': 6.7003, 'eval_samples_per_second': 16.865, 'eval_steps_per_second': 0.597, 'epoch': 8.8}\n",
      "{'loss': 12.0532, 'grad_norm': 104368.3828125, 'learning_rate': 0.0, 'epoch': 9.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700770b7de75442fa4d3d6f514999f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.660250425338745, 'eval_accuracy': 0.07079646017699115, 'eval_runtime': 5.1241, 'eval_samples_per_second': 22.053, 'eval_steps_per_second': 0.781, 'epoch': 9.8}\n",
      "{'train_runtime': 757.8764, 'train_samples_per_second': 5.938, 'train_steps_per_second': 0.04, 'train_loss': 12.082204182942709, 'epoch': 9.8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=12.082204182942709, metrics={'train_runtime': 757.8764, 'train_samples_per_second': 5.938, 'train_steps_per_second': 0.04, 'total_flos': 4.0092549156864e+16, 'train_loss': 12.082204182942709, 'epoch': 9.8})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output_dir\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_minds[\"train\"],\n",
    "    eval_dataset=encoded_minds[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=feature_extractor,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ¨ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨å·²ç»å¯¹æ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œå¯ä»¥ç”¨å®ƒæ¥è¿›è¡Œæ¨ç†ã€‚é¦–å…ˆåŠ è½½ç”¨äº†æ¨ç†çš„æ•°æ®ï¼ˆæ³¨æ„è¿™é‡Œä¸ºäº†æ¼”ç¤ºä½¿ç”¨åŒæ ·çš„æ•°æ®ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "audio_file = dataset[0][\"audio\"][\"path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°è¯•å¾®è°ƒæ¨¡å‹è¿›è¡Œæ¨ç†çš„æœ€ç®€å•æ–¹æ³•æ˜¯åœ¨pipeline()ä¸­ä½¿ç”¨å®ƒã€‚ä½¿ç”¨pipelineæ¨¡å‹å®ä¾‹åŒ–ä¸€ä¸ªç”¨äºéŸ³é¢‘åˆ†ç±»çš„æ¨¡å‹ï¼Œå¹¶å°†éŸ³é¢‘æ–‡ä»¶ä¼ é€’ç»™å®ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.08308025449514389, 'label': 'cash_deposit'},\n",
       " {'score': 0.08229406177997589, 'label': 'card_issues'},\n",
       " {'score': 0.07532459497451782, 'label': 'atm_limit'},\n",
       " {'score': 0.07338222116231918, 'label': 'high_value_payment'},\n",
       " {'score': 0.07311287522315979, 'label': 'app_error'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"audio-classification\", model=\"output_dir/checkpoint-30\")\n",
    "classifier(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœä¸ä½¿ç”¨pipelineï¼Œè€Œæ˜¯è‡ªå·±æ‰‹åŠ¨æ­å»ºæ¨¡å‹çš„è¯ï¼Œä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŠ è½½ç‰¹å¾æå–å™¨æ¥é¢„å¤„ç†éŸ³é¢‘æ–‡ä»¶å¹¶å°†å…¶è¿”å›inputä¸º PyTorch å¼ é‡ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"output_dir/checkpoint-30\")\n",
    "inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°†è¾“å…¥ä¼ é€’ç»™æ¨¡å‹å¹¶è¿”å›logistï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification\n",
    "import torch\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\"output_dir/checkpoint-30\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è·å–æ¦‚ç‡æœ€é«˜çš„ç±»ï¼Œå¹¶ä½¿ç”¨æ¨¡å‹çš„id2labelæ˜ å°„å°†å…¶è½¬æ¢ä¸ºæ ‡ç­¾ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cash_deposit'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_ids = torch.argmax(logits).item()\n",
    "predicted_label = model.config.id2label[predicted_class_ids]\n",
    "predicted_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
